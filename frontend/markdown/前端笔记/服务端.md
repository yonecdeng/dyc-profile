# 服务器

## 前后端数据交流



对于前端来说，后端主要是提供 http 接口来传输数据，而这种数据传输的方式主要有 5 种：

- url param
- query
- form-urlencoded
- form-data
- json

###  url param

我们可以把参数写在 url 中，比如：

```arduino
http://guang.zxg/person/1111
```

这里的 1111 就是路径中的参数（url param），服务端框架或者单页应用的路由都支持从 url 中取出参数。

### query

通过 url 中 ？后面的用 & 分隔的字符串传递数据。比如：

```ini
http://guang.zxg/person?name=guang&age=20
```

这里的 name 和 age 就是 query 传递的数据。

其中非英文的字符和一些特殊字符要经过编码，可以使用 encodeURIComponent 的 api 来编码：

```javascript
const query = "?name=" + encodeURIComponent('光') + "&age=20"

// ?name=%E5%85%89&age=20
```

或者使用封装了一层的 query-string 库来处理。

```javascript
const queryString = require('query-string');

queryString.stringify({
  name: '光',
  age: 20
});

// ?name=%E5%85%89&age=20
```

### form-urlencoded

直接用 form 表单提交数据就是这种，它和 query 字符串的方式的区别只是放在了 body 里，然后指定下 content-type 是 `application/x-www-form-urlencoded`。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b09a4411e26a40a0be7272dae3213eeb~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

因为内容也是 query 字符串，所以也要用 encodeURIComponent 的 api 或者 query-string 库处理下。

这种格式也很容易理解，get 是把数据拼成 query 字符串放在 url 后面，于是表单的 post 提交方式的时候就直接用相同的方式把数据放在了 body 里。

通过 & 分隔的 form-urlencoded 的方式需要对内容做 url encode，如果传递大量的数据，比如上传文件的时候就不是很合适了，因为文件 encode 一遍的话太慢了，这时候就可以用 form-data。

### form-data

fetch提交formdata时候不需要指定content-type。

form data 不再是通过 & 分隔数据，而是用 --------- + 一串数字做为 boundary 分隔符。因为不是 url 的方式了，自然也不用再做 url encode。

![img](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/af563395e1984ea5b90a19a04ce6730f~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

form-data 需要指定 content type 为 `multipart/form-data`，然后指定 boundary 也就是分割线。

body 里面就是用 boundary 分隔符分割的内容。

很明显，这种方式适合传输文件，而且可以传输多个文件。

但是毕竟多了一些只是用来分隔的 boundary，所以请求体会增大。

### json

form-urlencoded 需要对内容做 url encode，而 form data 则需要加很长的 boundary，两种方式都有一些缺点。如果只是传输 json 数据的话，不需要用这两种。

可以直接指定content type 为 application/json 就行：

![img](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c429166d35264cea922ebe45d399d4ef~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)





## 什么是正向代理和反向代理

一句话说明：正向代理就是代理客户端的请求，在一个面向客户端的位置。反向代理就是将客户端的请求分发到不同的服务器，在一个面向服务端的位置。

![2020-03-08-5ce95a07b18a071444-20200308191723379.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/13b3ec2e06d84f97b4536c5e6f19800d~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

### 正向代理

是指客户端通过代理服务器发送请求到目标服务器。客户端向代理服务器发送请求，代理服务器再将请求转发给目标服务器，并将服务器的响应返回给客户端。正向代理可以隐藏客户端的真实IP地址，提供匿名访问和访问控制等功能。它常用于跨越防火墙访问互联网、访问被封禁的网站等情况。

### 反向代理

是指客户端发送请求到代理服务器，代理服务器再将请求转发给后端的多个服务器中的一个或多个，并将后端服务器的响应返回给客户端。客户端并不直接访问后端服务器，而是通过反向代理服务器来获取服务。反向代理可以实现负载均衡、高可用性和安全性等功能。它常用于网站的高并发访问、保护后端服务器、提供缓存和SSL终止等功能。









## Nginx

### 什么是Nginx

Nginx是一个开源的高性能HTTP和反向代理服务器。它可以用于处理静态资源、负载均衡、反向代理和缓存等任务。它具有低内存消耗、高并发能力和良好的稳定性。

### 为什么使用Nginx

1. 高性能：Nginx采用事件驱动的异步架构，能够处理大量并发连接而不会消耗过多的系统资源。它的处理能力比传统的Web服务器更高，在高并发负载下表现出色。
2. 高可靠性：Nginx具有强大的容错能力和稳定性，能够在面对高流量和DDoS攻击等异常情况下保持可靠运行。它能通过健康检查和自动故障转移来保证服务的可用性。
3. 负载均衡：Nginx可以作为反向代理服务器，实现负载均衡，将请求均匀分发给多个后端服务器。这样可以提高系统的整体性能和可用性。
4. 静态文件服务：Nginx对静态资源（如HTML、CSS、JavaScript、图片等）的处理非常高效。它可以直接缓存静态文件，减轻后端服务器的负载。
5. 扩展性：Nginx支持丰富的模块化扩展，可以通过添加第三方模块来提供额外的功能，如gzip压缩、SSL/TLS加密、缓存控制等。

### 如何处理请求

Nginx处理请求的基本流程如下：

1. 接收请求：Nginx作为服务器软件监听指定的端口，接收客户端发来的请求。
2. 解析请求：Nginx解析请求的内容，包括请求方法（GET、POST等）、URL、头部信息等。
3. 配置匹配：Nginx根据配置文件中的规则和匹配条件，决定如何处理该请求。配置文件定义了虚拟主机、反向代理、负载均衡、缓存等特定的处理方式。
4. 处理请求：Nginx根据配置的处理方式，可能会进行以下操作：
   - 静态文件服务：如果请求的是静态资源文件，如HTML、CSS、JavaScript、图片等，Nginx可以直接返回文件内容，不必经过后端应用程序。
   - 反向代理：如果配置了反向代理，Nginx将请求转发给后端的应用服务器，然后将其响应返回给客户端。这样可以提供负载均衡、高可用性和缓存等功能。
   - 缓存：如果启用了缓存，Nginx可以缓存一些静态或动态内容的响应，在后续相同的请求中直接返回缓存的响应，减少后端负载并提高响应速度。
   - URL重写：Nginx可以根据配置的规则对URL进行重写，将请求从一个URL重定向到另一个URL或进行转换。
   - SSL/TLS加密：如果启用了SSL/TLS，Nginx可以负责加密和解密HTTPS请求和响应。
   - 访问控制：Nginx可以根据配置的规则对请求进行访问控制，例如限制IP访问、进行身份认证等。
5. 响应结果：Nginx根据处理结果生成响应报文，包括状态码、头部信息和响应内容。然后将响应发送给客户端。

### 操作

#### nginx 启动和关闭

```bash
进入目录：/usr/local/nginx/sbin
启动命令：./nginx
重启命令：nginx -s reload
快速关闭命令：./nginx -s stop
有序地停止，需要进程完成当前工作后再停止：./nginx -s quit
直接杀死nginx进程：killall nginx
```

#### 目录结构

```csharp
[root@localhost ~]# tree /usr/local/nginx
/usr/local/nginx

├── client_body_temp                 # POST 大文件暂存目录
├── conf                             # Nginx所有配置文件的目录
│   ├── fastcgi.conf                 # fastcgi相关参数的配置文件
│   ├── fastcgi.conf.default         # fastcgi.conf的原始备份文件
│   ├── fastcgi_params               # fastcgi的参数文件
│   ├── fastcgi_params.default      
│   ├── koi-utf
│   ├── koi-win
│   ├── mime.types                   # 媒体类型
│   ├── mime.types.default
│   ├── nginx.conf                   #这是Nginx默认的主配置文件，日常使用和修改的文件
│   ├── nginx.conf.default
│   ├── scgi_params                 # scgi相关参数文件
│   ├── scgi_params.default  
│   ├── uwsgi_params                 # uwsgi相关参数文件
│   ├── uwsgi_params.default
│   └── win-utf
├── fastcgi_temp                     # fastcgi临时数据目录
├── html                             # Nginx默认站点目录
│   ├── 50x.html                     # 错误页面优雅替代显示文件，例如出现502错误时会调用此页面
│   └── index.html                   # 默认的首页文件
├── logs                             # Nginx日志目录
│   ├── access.log                   # 访问日志文件
│   ├── error.log                   # 错误日志文件
│   └── nginx.pid                   # pid文件，Nginx进程启动后，会把所有进程的ID号写到此文件
├── proxy_temp                       # 临时目录
├── sbin                             # Nginx 可执行文件目录
│   └── nginx                       # Nginx 二进制可执行程序
├── scgi_temp                       # 临时目录
└── uwsgi_temp                       # 临时目录
```

#### 配置文件nginx.conf

```ini
# 启动进程,通常设置成和cpu的数量相等
worker_processes  1;

# 全局错误日志定义类型，[debug | info | notice | warn | error | crit]
error_log  logs/error.log;
error_log  logs/error.log  notice;
error_log  logs/error.log  info;

# 进程pid文件
pid        /var/run/nginx.pid;

# 工作模式及连接数上限
events {
    # 仅用于linux2.6以上内核,可以大大提高nginx的性能
    use   epoll;

    # 单个后台worker process进程的最大并发链接数
    worker_connections  1024;

    # 客户端请求头部的缓冲区大小
    client_header_buffer_size 4k;

    # keepalive 超时时间
    keepalive_timeout 60;

    # 告诉nginx收到一个新连接通知后接受尽可能多的连接
    # multi_accept on;
}

# 设定http服务器，利用它的反向代理功能提供负载均衡支持
http {
    # 文件扩展名与文件类型映射表义
    include       /etc/nginx/mime.types;

    # 默认文件类型
    default_type  application/octet-stream;

    # 默认编码
    charset utf-8;

    # 服务器名字的hash表大小
    server_names_hash_bucket_size 128;

    # 客户端请求头部的缓冲区大小
    client_header_buffer_size 32k;

    # 客户请求头缓冲大小
    large_client_header_buffers 4 64k;

    # 设定通过nginx上传文件的大小
    client_max_body_size 8m;

    # 开启目录列表访问，合适下载服务器，默认关闭。
    autoindex on;

    # sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，
    # 必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度
    sendfile        on;

    # 此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
    #tcp_nopush     on;

    # 连接超时时间（单秒为秒）
    keepalive_timeout  65;


    # gzip模块设置
    gzip on;               #开启gzip压缩输出
    gzip_min_length 1k;    #最小压缩文件大小
    gzip_buffers 4 16k;    #压缩缓冲区
    gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
    gzip_comp_level 2;     #压缩等级
    gzip_types text/plain application/x-javascript text/css application/xml;
    gzip_vary on;

    # 开启限制IP连接数的时候需要使用
    #limit_zone crawler $binary_remote_addr 10m;

    # 指定虚拟主机的配置文件，方便管理
    include /etc/nginx/conf.d/*.conf;


    # 负载均衡配置
    upstream aaa {
        # 请见上文中的五种配置
    }


   # 虚拟主机的配置
    server {

        # 监听端口
        listen 80;

        # 域名可以有多个，用空格隔开
        server_name www.aaa.com aaa.com;

        # 默认入口文件名称
        index index.html index.htm index.php;
        root /data/www/sk;

        # 图片缓存时间设置
        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)${
            expires 10d;
        }

        #JS和CSS缓存时间设置
        location ~ .*.(js|css)?${
            expires 1h;
        }

        # 日志格式设定
        #$remote_addr与 $http_x_forwarded_for用以记录客户端的ip地址；
        #$remote_user：用来记录客户端用户名称；
        #$time_local：用来记录访问时间与时区；
        #$request：用来记录请求的url与http协议；
        #$status：用来记录请求状态；成功是200，
        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；
        #$http_referer：用来记录从那个页面链接访问过来的；
        log_format access '$remote_addr - $remote_user [$time_local] "$request" '
        '$status $body_bytes_sent "$http_referer" '
        '"$http_user_agent" $http_x_forwarded_for';

        # 定义本虚拟主机的访问日志
        access_log  /usr/local/nginx/logs/host.access.log  main;
        access_log  /usr/local/nginx/logs/host.access.404.log  log404;

        # 对具体路由进行反向代理
        location /connect-controller {

            proxy_pass http://127.0.0.1:88;
            proxy_redirect off;
            proxy_set_header X-Real-IP $remote_addr;

            # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header Host $host;

            # 允许客户端请求的最大单文件字节数
            client_max_body_size 10m;

            # 缓冲区代理缓冲用户端请求的最大字节数，
            client_body_buffer_size 128k;

            # 表示使nginx阻止HTTP应答代码为400或者更高的应答。
            proxy_intercept_errors on;

            # nginx跟后端服务器连接超时时间(代理连接超时)
            proxy_connect_timeout 90;

            # 后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
            proxy_send_timeout 90;

            # 连接成功后，后端服务器响应的超时时间
            proxy_read_timeout 90;

            # 设置代理服务器（nginx）保存用户头信息的缓冲区大小
            proxy_buffer_size 4k;

            # 设置用于读取应答的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
            proxy_buffers 4 32k;

            # 高负荷下缓冲大小（proxy_buffers*2）
            proxy_busy_buffers_size 64k;

            # 设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
            # 设定缓存文件夹大小，大于这个值，将从upstream服务器传
            proxy_temp_file_write_size 64k;
        }

        # 动静分离反向代理配置（多路由指向不同的服务端或界面）
        location ~ .(jsp|jspx|do)?$ {
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_pass http://127.0.0.1:8080;
        }
    }
}
```

#### location

location指令的作用就是根据用户请求的URI来执行不同的应用

##### 语法

```css
location [ = | ~ | ~* | ^~ ] uri {...}
```

- `[ = | ~ | ~* | ^~ ]`：匹配的标识
  - `~`与`~*`的区别是：`~`区分大小写，`~*`不区分大小写
  - `^~`：进行常规字符串匹配后，不做正则表达式的检查
- `uri`：匹配的网站地址
- `{...}`：匹配uri后要执行的配置段

##### 举例

```ini
location = / {
    [ configuration A ]
}
location / {
    [ configuration B ]
}
location /sk/ {
    [ configuration C ]
}
location ^~ /img/ {
    [ configuration D ]
}
location ~* .(gif|jpg|jpeg)$ {
    [ configuration E ]
}
```

- `= /` 请求 `/` 精准匹配A，不再往下查找
- `/` 请求`/index.html`匹配B。首先查找匹配的前缀字符，找到最长匹配是配置B，接着又按照顺序查找匹配的正则。结果没有找到，因此使用先前标记的最长匹配，即配置B。
- `/sk/` 请求`/sk/abc` 匹配C。首先找到最长匹配C，由于后面没有匹配的正则，所以使用最长匹配C。
- `~* .(gif|jpg|jpeg)$` 请求`/sk/logo.gif` 匹配E。首先进行前缀字符的查找，找到最长匹配项C，继续进行正则查找，找到匹配项E。因此使用E。
- `^~` 请求`/img/logo.gif`匹配D。首先进行前缀字符查找，找到最长匹配D。但是它使用了`^~`修饰符，不再进行下面的正则的匹配查找，因此使用D。

#### 单页面应用刷新404问题

```bash
location / {
        try_files $uri $uri/ /index.html;
    }
```

#### 配置跨域请求

```ini
server {
    listen   80;
    location / {
        # 服务器默认是不被允许跨域的。
        # 配置`*`后，表示服务器可以接受所有的请求源（Origin）,即接受所有跨域的请求
        add_header Access-Control-Allow-Origin *;
        
        add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';
        add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';
        
        # 发送"预检请求"时，需要用到方法 OPTIONS ,所以服务器需要允许该方法
        # 给OPTIONS 添加 204的返回，是为了处理在发送POST请求时Nginx依然拒绝访问的错误
        if ($request_method = 'OPTIONS') {
            return 204;
        }
    }
}
```

#### 开启gzip压缩

```bash
 # gzip模块设置
    gzip on;               #开启gzip压缩输出
    gzip_min_length 1k;    #最小压缩文件大小
    gzip_buffers 4 16k;    #压缩缓冲区
    gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
    gzip_comp_level 2;     #压缩等级
    
    # 设置什么类型的文件需要压缩
    gzip_types text/plain application/x-javascript text/css application/xml;
    
    # 用于设置使用Gzip进行压缩发送是否携带“Vary:Accept-Encoding”头域的响应头部
    # 主要是告诉接收方，所发送的数据经过了Gzip压缩处理
    gzip_vary on;
```





## swagger

### OpenAPI schema

OpenAPI 3.0 规范由 8 个根对象组成：

1. openapi
2. info
3. servers
4. paths
5. components
6. security
7. tags
8. externalDocs

OpenAPI 的其余功能都是基于这 8 根对象扩展而成，凡是包含以上对象并且扩展名为 `json`，`yaml` 的文件，我们可以将其视为符合 **OpenAPI 规范的描述文件** 

下面介绍几个常用的对象，抄这里的https://www.cnblogs.com/xiao2shiqi/p/16412813.html，没介绍到的话也去刚刚网址看吧



#### paths 对象

`paths` 对象包含真正的 API 信息内容，它的每个项都包含一个可操作的 `endpoint` 操作对象。

看一个简单示例：

```yaml
paths:
  /pet:
    get:
```

以上信息描述一个 `/pet` 的 `endpoint` ，它只包含一个 `get` 操作对象，类似 `get` 操作对象（也称 Operation Objects）也包含以下属性（不需要声明所有属性）：

- `tags`：用于对 endpoint 进行分组的组名

- `summary`：操作对象的摘要信息，最好限制在 5-10 字以内，主要作为概览展示

- `description`：操作对象的描述信息，尽可能的详细，展示细节信息

- `operationId`：操作对象的唯一 ID

- `parameters`该端点的请求参数对象，描述如下，（requestBody描述不在此列包含系列属）

  - name：参数名称

  - in：参数出现的位置，通常是 `header`，`path`，`query`，`cookie`

  - description：参数的描述（支持 markdown）

  - required：必填项

  - deprecated：是否弃用

  - allowEmptyValue：允许提交空值

  - style：参数序列化方式

  - explode：与数组相关的参数

  - schema：参数的模型

  - example：媒体类型的示例

    - `parameters` 的示例用法（包含一个参数的 `get` 方法）：

    ```yaml
    paths:
      /weather:
        get:
          tags:
          - Current Weather Data
          summary: "Call current weather data for one location."
          description: "^_^"
          operationId: CurrentWeatherData
          parameters:
          - name: q
            in: query
            description: "^_^"
            schema:
              type: string
    ```

- `requestBody`：请求主体的描述，还可以包含一个指向 `components` 的 `$ref` 指针

- `response`：响应主体的描述，通常使用标准的 HTTP 状态码，可以包含指向 `components` 的 `$ref` 指针

  - responses 用于描述接口的响应对象，可以直接描述，如下：

    ```yaml
    responses:
      200:
        description: Successful response
        content:
          application/json:
            schema:
              title: Sample
              type: object
              properties:
                placeholder:
                  type: string
                  description: Placeholder description
    
      404:
        description: Not found response
        content:
          text/plain:
            schema:
              title: Weather not found
              type: string
              example: Not found
    ```

- `callbacks`：回调对象和回调信息的描述，较为少见，不过多介绍

- `deprecated`：标识该 `path` 是否被弃用

- `security`：仅用于覆盖全局的安全授权方法

- `servers`：仅用于覆盖全局的服务器访问对象







#### components 对象

在 `components` 中主要可以定义重复使用的对象，以便其他对象使用 `$ref` 关键字直接引用和声明

##### 在 parameters 中重用对象

我们可以把刚才对 parameters 的描述移动到 components 中来，如下：

```yaml
components:
  parameters:
    q:
      name: q
      in: query
      description: "………………"
      schema:
        type: string
    id:
      name: id
      in: query
      description: "…………"
      schema:
        type: string
```

然后我们可以在 paramters 中直接引用它，如下：

```yaml
paths:
  /weather:
    get:
     // ......
      parameters:
        - $ref: '#/components/parameters/q'
        - $ref: '#/components/parameters/id'
			// .......
```



##### 在 reponses 中重用对象

可在 reponses 中引用已经声明的对象，如下：

```yaml
responses:
  200:
    description: Successful response
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/200'
```

它在 yaml 中的描述如下：

```yaml
components:
  schemas:
    200:
      title: Successful response
      type: object
      properties:
        base:
          type: string
          description: Internal parameter
          example: cmc stations
        visibility:
          type: integer
          description: Visibility, meter
          example: 16093
```





通过 `components` 定义的对象都会在 Swagger UI 下方通过 `Schemas` 进行展示，如下：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-19-11-26-image-20231219112637229.png" alt="image-20231219112637229" style="zoom:50%;" />







#### security 对象

security 用于描述 API 的安全信息和访问授权协议等信息，OpenAPI 支持最常见的四种授权方案，如下：

- API key
- HTTP
- OAuth 2.0
- Open ID Connect

这里使用 API Key 作为演示，在 OpenAPI 文档的根目录添加安全对象：

```yaml
security:
  - app_id: []
```

这样所有的路径都会使用 `security` 描述的 `app_id` 安全方法，我们通常会在 `components` 中添加 `security` 对象，这样的描述信息会更加的详细，如下：

```yaml
components:
  ...
  securitySchemes:
    app_id:
      type: apiKey
      description: API key to authorize requests.
      name: appid
      in: query
```

security 对象的属性内容：

- type：授权协议，枚举值有：`apiKey`、`http`、`oauth2`、`openIdConnect`
- description：安全方法的描述，尽可能的详细，包含使用示例
- name：安全密钥 `apiKey` 在 HTTP Header 请求中的名字
- in：安全密钥 `apiKey` 在 HTTP 传输中的位置，枚举值有：`query`，`header`，`cookie`
- …………

在添加以上的描述信息后，Swagger UI 会显示安全任何的相关标识，如下：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-19-11-33-image-20231219113346640.png" alt="image-20231219113346640" style="zoom:50%;" />

点击 `Authorize` 会显示更多的安全信息：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-19-11-34-image-20231219113420425.png" alt="image-20231219113420425" style="zoom:25%;" />

当你在 `Value` 输入你的访问秘钥时，Swagger 会在访问 API 的时候，根据你的设定访问你的 API，如下：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-19-11-34-image-20231219113448939.png" alt="image-20231219113448939" style="zoom:25%;" />

#### tags 对象

该对象主要是对 OpenAPI 中的多个访问路径进行分组，使用示例如下：

我们为一个请求路径添加 `tags` 信息：

```yaml
paths:
  /pets:
    get:
      summary: List all pets
      operationId: listPets
      tags:
        - pets
```

这表示该请求路径属于 `pets` 分组，然后我们在根目录级别添加 `tags` 属性，来为分组信息进行描述：

```yaml
tags:
  - name: pets
    description: "Chimelong Animal Happy World"
```

然后我们来看看 Swagger UI 对于分组信息的展示，如下：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-19-11-36-image-20231219113627292.png" alt="image-20231219113627292" style="zoom:25%;" />









### 利用schema生成前端代码

明白了上面schema的数据结构含义，你想用来生成啥都没问题。

生成mock，可以参考这个https://reeli.github.io/blog/tools_swagger-to-mocks.html#%E7%94%9F%E6%88%90-mock-%E6%95%B0%E6%8D%AE。用到了faker.js这个库

生成ts类型，可以参考这个https://github.com/drwpow/openapi-typescript/blob/main/packages/openapi-typescript/README.md





# 后端系统

## Server-side-render(ssr)

一个应用渲染静态页面的过程，其实可以分为以下三个步骤：

- 模板页面的渲染：即 HTML中 body 标签下的 dom 内容，像我们平时写一个基于 React(反应) 或是 Vue 的前后端分离项目，首先我们会去编写对应页面的模板模块，再写相关的数据请求，最后统一导出进行页面的渲染。

- 路由的匹配：一个 Web(网络) 工程下可能会有多个模板页面需要渲染，我们会使用路由去对应指定的模板页面进行渲染，体现在浏览器中，也就是我们域名后的后缀。

- header标签的修改：模板页面本身是没办法去修改页面的 header 标签的，但是修改 header 标签的需求其实并不少见，类似修改站点的标题， 或是进行多媒体适配，可能都需要对 header 标签有一定修改。







### CSR、SSR、SSG

预渲染是当今比较主流的优化手段，主要包括服务端渲染(SSR)和静态站点生成(SSG)这两种技术。

在选择上，如果我们的应用存在首屏加载优化需求，SEO需求时，就可以考虑SSR。

#### CSR

CSR 的工作流程：

客户端向服务器或 CDN 发送请求，获取静态的 HTML 页面。注意，此时获取的HTML 页面通常是空页面。在 HTML 页面中，会包含 `<style>`、`<link>` 和`<script>` 等标签。浏览器在得到该页面后，不会渲染出任何内容，所以从用户的视角看，此时页面处于“白屏”阶段。<mark>（所以 `白屏`问题就是CSR带来的，想根治就SSR吧或者SSG，反正就是返回的html得有东西，别就一个空的`<div id='app'/>`）</mark>

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2024-01-12-18-01-image-20240112180138631.png" alt="image-20240112180138631" style="zoom:33%;" />





csr确实一般是单页应用，多页应用的话肯定有不同的html。

CSR应用只会首次请求html文件，后续只需要请求JSON数据即可，因此节约流量，服务端压力也较小。但是首屏加载的时间会变长，而且SEO不友好。

它的 HTML 产物一般是如下的结构:

```ts
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title></title>
  <link rel="stylesheet" href="xxx.css" />
</head>
<body>
  <!-- 一开始没有页面内容 -->
  <div id="root"></div>
  <!-- 通过 JS 执行来渲染页面 -->
  <script src="xxx.chunk.js"></script>
</body>
</html>
```

当浏览器拿到如上的 HTML 内容之后，并不能渲染完整的页面内容，因为此时的 body 中基本只有一个空的 div 节点，并没有填入真正的页面内容。而接下来浏览器开始下载并执行 JS 代码，经历了框架初始化、数据请求、DOM 插入等操作之后才能渲染出完整的页面。也就是说，在 CSR 中完整的页面内容本质上通过 JS 代码执行之后才能够渲染。这主要会导致两个方面的问题:

- **首屏加载速度比较慢**。首屏加载需要依赖 JS 的执行，下载和执行 JS 都可能是非常耗时的操作，尤其是在一些网络不佳的场景，或者性能敏感的低端机下。
- **对 SEO(搜索引擎优化) 不友好**。页面 HTML 没有具体的页面内容，导致搜索引擎爬虫无法获取关键词信息，导致网站排名受到影响。

#### SSR

<font color="red">服务端</font>生成好**完整的 HTML 内容**，直接返回给浏览器，浏览器能够根据 HTML 渲染出完整的首屏内容，而不需要依赖 JS 的加载，这样一方面能够降低首屏渲染的时间，另一方面也能将完整的页面内容展现给搜索引擎的爬虫，利于 SEO。而另一方面，由于服务端的网络环境更优，可以更快地获取到页面所需的数据，也能节省浏览器请求数据的时间。

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2024-01-12-17-57-image-20240112175706981.png" alt="image-20240112175706981" style="zoom:33%;" />

(1) 用户通过浏览器请求站点。(2) 服务器请求 API 获取数据。(3) 接口返回数据给服务器。(4) 服务器根据模板和获取的数据拼接出最终的 HTML 字符串。(5) 服务器将 HTML 字符串发送给浏览器，浏览器解析 HTML 内容并渲染。

当用户再次通过超链接进行页面跳转，会重复上述 5 个步骤。





SSR 中只能生成页面的内容和结构，并不能完成事件绑定，因此需要在浏览器中执行 CSR 的 JS 脚本，完成事件绑定，让页面拥有交互的能力，这个过程被称作`hydrate`(翻译为`注水`或者`激活`)。同时，像这样服务端渲染 + 客户端 hydrate 的应用也被称为`同构应用`。

水合（hydrateRoot）
此处水合是指后端数据达到前端后，js绑定事件，才能够响应用户的操作或者DOM的更新。
组件在服务器拉取数据，并在服务端首次渲染。
脱水，对组件进行脱水，变成HTML字符串，脱去交互事件，成为风干标本快照。
注水，发送到客户端后，重新注入数据（交互的事件），重新变成可交互组件。



在 Vue 场景下，通常可以选择 [Nuxt.js](https://link.juejin.cn/?target=https%3A%2F%2Fnuxtjs.org%2F)、[Quasar](https://link.juejin.cn/?target=https%3A%2F%2Fquasar.dev%2F)、[`@vue/server-renderer`](https://link.juejin.cn/?target=https%3A%2F%2Fvuejs.org%2Fguide%2Fscaling-up%2Fssr.html) 等方案实现 SSR，这些技术的底层逻辑都包含三个大的步骤：

- 编译时，将同一组件构建为适合在客户端、服务器运行的两份副本；
- 服务端接收到请求时，调用 Render 工具将组件渲染为 HTML 字符串，并返回给客户端；
- 客户端运行 HTML，并再次执行组件代码，“激活(Hydrate)” 组件。






SSR 不是银弹，依然带来了不少新问题：

- 更高的架构复杂度，这意味着更高的维护、扩展、学习成本；
- Node 与浏览器环境不完全匹配，部分浏览器特定的代码，只能在某些生命周期钩子函数中使用；一些外部扩展库 (external library) 可能需要特殊处理，才能在 SSR 中运行；
- 组件要求更高，需要兼容 Node.js Server 运行环境；
- 服务端负载更高，毕竟相较于纯粹提供静态资源的 SPA 形式，SSR 需要在 Node 进程中执行大量 CPU 运算以渲染 HTML 片段。

#### SSG

 [Static Site Generation](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fchrisvfritz%2Fprerender-spa-plugin) (或叫 Pre-renderer) 方式

 SSG 可以在<font color="red">构建阶段</font>执行代码生成完整的 HTML 内容，它与 SSR 最大的不同在于 HTML 的生成在构建阶段完成，而不是在服务器的运行时。SSG 同样可以给浏览器完整的 HTML 内容，不依赖于 JS 的加载，可以有效提高页面加载性能。不过相比 SSR，SSG 的内容往往动态性不够，适合比较静态的站点，比如文档、博客等场景。

缺点是 会导致构建时长变慢。

在 Webpack4 环境下，可选择 [prerender-spa-plugin](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fchrisvfritz%2Fprerender-spa-plugin) 实现 SSG 功能，但实测发现该插件并不兼容 Webpack5

在vite下用vite-ssg，可到工程化的vite下看具体实现。



如果ssg里有一些依据接口的分支，比如如果接口返回的值是某某就展示a，如果是接口返回的是另一个值我就要展示b，那就按没有这个接口值的情况来处理。比如：

```js
 // HomePage.vue
<h1 v-if="coinBalance">有{{ coinBalance }}</h1>
        <h1 v-if="coinBalance && coinBalance > 1000">有大于{{ coinBalance }}</h1>
        <h1 v-else-if="coinBalance && coinBalance < 1000">有小于{{ coinBalance }}</h1>
        <h1 v-else>无{{ coinBalance }}</h1>
// 这个ssg打包出来的index.html里就只有 最下面那个 ‘无’
```



#### ISR（Incremental Static Regeneration）增量静态生成


ISR最早由 Next.js 在 9.5 版本中提出，它结合了 SSG 和 SSR 的优势。

核心思想是将内容区分为主要内容和次要内容。主要内容的静态页面采用SSG的方式在构建时生成。而对于次要内容则借鉴SSR得方式保持动态，在用户首次访问时进行渲染。一旦渲染完成，生成的静态页面被缓存，并在后续的请求中被直接提供，以提高性能和响应速度。

后续更新遵循 stale-while-revalidate 的逻辑，即始终返回 CDN 的缓存数据（无论是否过期）；如果数据已经过期，那么触发异步的预渲染，异步更新 CDN 的缓存。



#### DPR（Distributed Persistent Rendering）分布式的持续渲染

DPR是由Netlify提出个一个提案，详见Distributed Persistent Rendering: a new idea in the Jamstack to make deploys faster and bring a wider range of use cases.

DPR 本质上讲，是对 ISR 的模型做了几处改动，并且搭配上 CDN 的能力：

1、去除了 fallback 行为，而是直接用 On-demand Builder（按需构建器）来响应未经过预渲染的页面，然后将结果缓存至 CDN；

2、数据页面过期时，不再响应过期的缓存页面，而是 CDN 回源到 Builder 上，渲染出最新的数据；

3、每次发布新版本时，自动清除 CDN 的缓存数据。














### ssg/ssr的作用

#### Ssg/ssr解决SPA的首页加载慢(amp)和seo问题

Ssg: 客户端拿到html>发起请求(因为主接口预请求，不然这个得在js执行)->请求js->js执行->绘制页面中动态部分->fmp；

ssr: server执行js->请求接口->绘制html->客户端拿到html->fmp；由于前面都是在server做的会比较快，而且内网请求接口就几毫秒的事

所以为啥老说动态数据多的就用ssr，动态数据少的用ssg，原因一是ssr核心提速就在于首页的接口请求。原因二是没啥动态数据的话ssg直接构建就行了。你可以理解成ssg是ssr在动态数据少的时候的一种优化手段，当然动态数据多的时候也能用，就只渲染静态的部分，动态的都为空或loading呗，但页面太多动态数据就确实意义不大了，还导致你构建的时长变慢。

#### 解决不了tti慢的问题

ssg（static site generation）/ssr主要的问题在于这类方案仍然会下载`全量的客户端 JS `及执行`全量的组件 Hydrate 过程`，造成页面的首屏 TTI 劣化。

tti的话由于都要执行js之后才行，所以ssr对于ssg的提升就只在于加快了接口的响应时间。而ssg对于tti则没有什么提升。





## 同构

同构”一词指的是一份代码既在服务端运行，又在客户端运行。因此，在编写组件代码时，应该额外注意因代码运行环境的不同所导致的差异。

SSR 中只能生成页面的内容和结构，同构渲染仍然需要像 CSR 那样等待 JavaScript 资源加载完成，并且客户端激活完成后，完成事件绑定，让页面拥有交互的能力。因此，理论上同构渲染无法提升可交互时间。，这个过程被称作`hydrate`(翻译为`注水`或者`激活`)。像这样服务端渲染 + 客户端 hydrate 的应用也被称为`同构应用`。服务端渲染的是应用程序的快照，所谓快照，指的是在当前数据状态下页面应该呈现的内容。





### **同构的 生命周期**

借用一张Webpack官方的图来表示SSR应用的两大周期：**构建时** +  **运行时**。

![image-20231126171641522](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-11-26-17-16-image-20231126171641522.png)

#### **构建时**

1. 构建出两套代码，分别用于客户端侧和服务端侧运行。

   <img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-11-29-19-38-image-20231129193840125.png" alt="image-20231129193840125" style="zoom:50%;" />

2. **移除样式代码的引入**。直接引入一行 css 在服务端其实是无法执行的，因为 Node.js并不能解析 CSS 的内容。但 `CSS Modules` 的情况除外，如下所示:

```ts
import styles from './index.module.css'
// 这里的 styles 是一个对象，如{ "container": "xxx" }，而不是 CSS 代码
console.log(styles)
```

3. **依赖外部化(external(外部))**。对于某些第三方依赖我们并不需要使用构建后的版本，而是直接从 `node_modules` 中读取，比如 `react-dom`，这样在 `SSR 构建`的过程中将不会构建这些依赖，从而极大程度上加速 SSR 的构建。













#### **运行时**

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-11-29-20-23-image-20231129202303150.png" alt="image-20231129202303150" style="zoom:50%;" />

**加载 SSR 入口模块**。在这个阶段，我们需要确定 SSR 构建产物的入口，即组件的入口在哪里，并加载对应的模块。

**进行数据预取**。这时候 Node 侧会通过查询数据库或者网络请求来获取应用所需的数据。如何使服务端和客户端共享**数据模型**：服务端在输出html文件前**将请求获取的数据注入到window**某个属性上。客户端获取到html文件后，**获取了window上的数据，并将该数据存在客户端store中**。

**渲染组件**。这个阶段为 SSR 的核心，主要将第 `1` 步中加载的组件渲染成 HTML 字符串或者 Stream流。

**HTML 拼接**。在组件渲染完成之后，我们需要拼接完整的 HTML 字符串，并将其作为响应返回给浏览器。











#### 同构应用代码的执行过程：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-11-26-17-18-image-20231126171859153.png" alt="image-20231126171859153" style="zoom:50%;" />





### 工程化问题

vue官网上的一些成熟方案https://cn.vuejs.org/guide/scaling-up/ssr.html#higher-level-solutions

以上我们基本实现了 SSR 核心的`构建`和`运行时`功能，可以初步运行一个基于 Vite 的 SSR 项目，但在实际的场景中仍然是有不少的工程化问题需要我们注意。下面我就和你一起梳理一下到底需要考虑哪些问题，以及相应的解决思路是如何的。

#### 1. 路由管理

在 SPA 场景下，对于不同的前端框架，一般会有不同的路由管理方案，如 Vue 中的 `vue-router`、React 的`react-router`。不过归根结底，路由方案在 SSR 过程中所完成的功能都是差不多的:

1. 告诉框架现在渲染哪个路由。在 Vue 中我们可以通过 `router.push` 确定即将渲染的路由，React 中则通过 `StaticRouter` 配合`location`参数来完成。
2. 设置 `base` 前缀。规定路径的前缀，如`vue-router` 中 [base 参数](https://link.juejin.cn/?target=https%3A%2F%2Frouter.vuejs.org%2Fzh%2Fguide%2Fmigration%2F%23%E7%A7%BB%E5%8A%A8%E4%BA%86-base-%E9%85%8D%E7%BD%AE)、`react-router`中`StaticRouter`组件的 [basename](https://link.juejin.cn/?target=https%3A%2F%2Fv5.reactrouter.com%2Fweb%2Fapi%2FStaticRouter)。

#### 2. 全局状态管理

对于全局的状态管理而言，对于不同的框架也有不同的生态和方案，比如 Vue 中的 [Vuex](https://link.juejin.cn/?target=https%3A%2F%2Fvuex.vuejs.org%2F)、[Pinia](https://link.juejin.cn/?target=https%3A%2F%2Fpinia.vuejs.org%2F)，React 中的 [Redux](https://link.juejin.cn/?target=https%3A%2F%2Fredux.js.org%2Fintroduction%2Fgetting-started)、[Recoil](https://link.juejin.cn/?target=https%3A%2F%2Frecoiljs.org%2Fzh-hans%2F)。各个状态管理工具的用法并不是本文的重点，接入 SSR 的思路也比较简单，在`预取数据`阶段初始化服务端的 `store` ，将异步获取的数据存入 `store` 中，然后在 `拼接 HTML`阶段将数据从 store 中取出放到数据 script 标签中，最后在客户端 hydrate 的时候通过 window 即可访问到预取数据。

> 需要注意的服务端处理许多不同的请求，对于每个请求都需要**分别**初始化 store，即一个请求一个 store，不然会造成全局状态污染的问题。

#### 3. CSR 降级

在某些比较极端的情况下，我们需要降级到 CSR，也就是客户端渲染。一般而言包括如下的降级场景:

- 1. 服务器端**预取数据**失败，需要降级到客户端获取数据。
- 1. 服务器出现异常，需要返回**兜底的 CSR 模板**，完全降级为 CSR。
- 1. 本地**开发调试**，有时需要跳过 SSR，仅进行 CSR。

对于第一种情况，在客户端入口文件中需要有重新获取数据的逻辑，我们可以进行这样的补充:

```ts
ts
复制代码// entry-client.tsx
import React from 'react'
import ReactDOM from 'react-dom'
import './index.css'
import App from './App'

async function fetchData() {
  // 客户端获取数据
}


async fucntion hydrate() {
  let data;
  if (window.__SSR_DATA__) {
    data = window.__SSR_DATA__;
  } else {
    // 降级逻辑 
    data = await fetchData();
  }
  // 也可简化为 const data = window.__SSR_DATA__ ?? await fetchData();
  ReactDOM.hydrate(
    <React.StrictMode>
      <App data={data}/>
    </React.StrictMode>,
    document.getElementById('root')
  )
}
```

对于第二种场景，即`服务器执行出错`，我们可以在之前的 SSR 中间件逻辑追加 catch 逻辑:

```ts
ts
复制代码async function createSsrMiddleware(app: Express): Promise<RequestHandler> {
  return async (req, res, next) => {
    try {
      // SSR 的逻辑省略
    } catch(e: any) {
      vite?.ssrFixStacktrace(e);
      console.error(e);
      // 在这里返回浏览器 CSR 模板内容
    }
  }
}
```

对于第三种情况，我们可以通过通过 `?csr` 的 url query 参数来强制跳过 SSR，在 SSR 中间件添加如下逻辑:

```ts
ts
复制代码async function createSsrMiddleware(app: Express): Promise<RequestHandler> {
  return async (req, res, next) => {
    try {
      if (req.query?.csr) {
        // 响应 CSR 模板内容
        return;
      }
      // SSR 的逻辑省略
    } catch(e: any) {
      vite?.ssrFixStacktrace(e);
      console.error(e);
    }
  }
}
```

#### 4. 浏览器 API 兼容

由于 Node.js 中不能使用浏览器里面诸如 `window`、`document`之类的 API，因此一旦在服务端执行到这样的 API 会报如下的错误：

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0d756366a02140f089046dab28ff2b2b~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

那么如何来解决这个问题呢？

首先我们可以通过`import.meta.env.SSR`这个 Vite 内置的环境变量来判断是否处于 SSR 环境，以此来规避业务代码在服务端出现浏览器的 API:

```ts
ts
复制代码if (import.meta.env.SSR) {
  // 服务端执行的逻辑
} else {
  // 在此可以访问浏览器的 API
}
```

当然，我们也可以通过 polyfill 的方式，在 Node 中注入浏览器的 API，使这些 API 能够正常运行起来，解决如上的问题。我推荐使用一个比较成熟的 polyfill 库 `jsdom`，使用方式如下:

```ts
ts
复制代码const jsdom = require('jsdom');
const { window } = new JSDOM(`<!DOCTYPE html><p>Hello world</p>`);
const { document } = window;
// 挂载到 node 全局
global.window = window;
global.document = document;
```

#### 5. 自定义 Head

在 SSR 的过程中，我们虽然可以在决定组件的内容，即`<div id="root"></div>`这个容器 div 中的内容，但对于 HTML 中`head`的内容我们无法根据**组件的内部状态**来决定，比如对于一个直播间的页面，我们需要在服务端渲染出 title 标签，title 的内容是不同主播的直播间名称，不能在代码中写死，这种情况怎么办？

React 生态中的 [react-helmet](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fnfl%2Freact-helmet) 以及 Vue 生态中的 [vue-meta](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fnuxt%2Fvue-meta) 库就是为了解决这样的问题，让我们可以直接在组件中写一些 Head 标签，然后在服务端能够拿到组件内部的状态。这里我以一个`react-helmet`例子来说明:

```ts
ts
复制代码// 前端组件逻辑
import { Helmet } from "react-helmet";

function App(props) {
  const { data } = props;
  return {
    <div>
       <Helmet>
        <title>{ data.user }的页面</title>
        <link rel="canonical" href="http://mysite.com/example" />
      </Helmet>
    </div>
  }
}
// 服务端逻辑
import Helmet from 'react-helmet';

// renderToString 执行之后
const helmet = Helmet.renderStatic();
console.log("title 内容: ", helmet.title.toString());
console.log("link 内容: ", helmet.link.toString())
```

启动服务后访问页面，可以发现终端能打印出如下的信息:

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9a3e42dce502496badfc482ea75acceb~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

如此一来，我们就能根据组件的状态确定 Head 内容，然后在`拼接 HTML`阶段将这些内容插入到模板中。

#### 6. 流式渲染

在不同前端框架的底层都实现了流式渲染的能力，即边渲染边响应，而不是等整个组件树渲染完毕之后再响应，这么做可以让响应提前到达浏览器，提升首屏的加载性能。Vue 中的 [renderToNodeStream](https://link.juejin.cn/?target=https%3A%2F%2Fwww.npmjs.com%2Fpackage%2F@vue%2Fserver-renderer) 和 React 中的 [renderToNodeStream](https://link.juejin.cn/?target=https%3A%2F%2Freactjs.org%2Fdocs%2Freact-dom-server.html%23rendertonodestream) 都实现了流式渲染的能力, 大致的使用方式如下:

```ts
ts
复制代码import { renderToNodeStream } from 'react-dom/server';

// 返回一个 Nodejs 的 Stream 对象
const stream = renderToNodeStream(element);
let html = ''

stream.on('data', data => {
  html += data.toString()
  // 发送响应
})

stream.on('end', () => {
  console.log(html) // 渲染完成
  // 发送响应
})

stream.on('error', err => {
  // 错误处理
})
```

不过，流式渲染在我们带来首屏性能提升的同时，也给我们带来了一些限制: **如果我们需要在 HTML 中填入一些与组件状态相关的内容，则不能使用流式渲染**。比如`react-helmet`中自定义的 head 内容，即便在渲染组件的时候收集到了 head 信息，但在流式渲染中，此时 HTML 的 head 部分已经发送给浏览器了，而这部分响应内容已经无法更改，因此 `react-helmet` 在 SSR 过程中将会失效。

#### 7. SSR 缓存

SSR 是一种典型的 CPU 密集型操作，为了尽可能降低线上机器的负载，设置缓存是一个非常重要的环节。在 SSR 运行时，缓存的内容可以分为这么几个部分:

- `文件读取缓存`。尽可能避免多次重复读磁盘的操作，每次磁盘 IO 尽可能地复用缓存结果。如下代码所示:

```ts
ts
复制代码function createMemoryFsRead() {
  const fileContentMap = new Map();
  return async (filePath) => {
    const cacheResult = fileContentMap.get(filePath);
    if (cacheResult) {
      return cacheResult;
    }
    const fileContent = await fs.readFile(filePath);
    fileContentMap.set(filePath, fileContent);
    return fileContent;
  }
}

const memoryFsRead = createMemoryFsRead();
memoryFsRead('file1');
// 直接复用缓存
memoryFsRead('file1');
```

- `预取数据缓存`。对于某些实时性不高的接口数据，我们可以采取缓存的策略，在下次相同的请求进来时复用之前预取数据的结果，这样预取数据过程的各种 IO 消耗，也可以一定程度上减少首屏时间。
- `HTML 渲染缓存`。拼接完成的`HTML`内容是缓存的重点，如果能将这部分进行缓存，那么下次命中缓存之后，将可以节省 `renderToString`、`HTML 拼接`等一系列的消耗，服务端的性能收益会比较明显。

对于以上的缓存内容，具体的缓存位置可以是：

- 1. `服务器内存`。如果是放到内存中，需要考虑缓存淘汰机制，防止内存过大导致服务宕机，一个典型的缓存淘汰方案是 [lru-cache](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fisaacs%2Fnode-lru-cache) (基于 LRU 算法)。
- 1. [Redis 数据库](https://link.juejin.cn/?target=https%3A%2F%2Fgithub.com%2Fredis%2Fnode-redis)，相当于以传统后端服务器的设计思路来处理缓存。
- 1. CDN 服务。我们可以将页面内容缓存到 CDN 服务上，在下一次相同的请求进来时，使用 CDN 上的缓存内容，而不用消费源服务器的资源。对于 CDN 上的 SSR 缓存，大家可以通过阅读[这篇文章](https://juejin.cn/post/6887884087915184141#heading-8)深入了解。

> 需要补充的是，Vue 中另外实现了[组件级别的缓存](https://link.juejin.cn/?target=https%3A%2F%2Fssr.vuejs.org%2Fzh%2Fguide%2Fcaching.html%23%E7%BB%84%E4%BB%B6%E7%BA%A7%E5%88%AB%E7%BC%93%E5%AD%98-component-level-caching)，这部分缓存一般放在内存中，可以实现更细粒度的 SSR 缓存。

#### 8. 性能监控

在实际的 SSR 项目中，我们时常会遇到一些 SSR 线上性能问题，如果没有一个完整的性能监控机制，那么将很难发现和排查问题。对于 SSR 性能数据，有一些比较通用的指标:

- SSR 产物加载时间
- 数据预取的时间
- 组件渲染的时间
- 服务端接受请求到响应的完整时间
- SSR 缓存命中情况
- SSR 成功率、错误日志

我们可以通过`perf_hooks`来完成数据的采集，如下代码所示:

```ts
ts
复制代码import { performance, PerformanceObserver } from 'perf_hooks';

// 初始化监听器逻辑
const perfObserver = new PerformanceObserver((items) => {
  items.getEntries().forEach(entry => { 
    console.log('[performance]', entry.name, entry.duration.toFixed(2), 'ms');
  });
  performance.clearMarks();
});

perfObserver.observe({ entryTypes: ["measure"] })

// 接下来我们在 SSR 进行打点
// 以 renderToString  为例
performance.mark('render-start');
// renderToString 代码省略
performance.mark('render-end');
performance.measure('renderToString', 'render-start', 'render-end');
```

接着我们启动服务后访问，可以看到如下的打点日志信息:

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c1b1fca61664929be812d4153fdbc13~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

同样的，我们可以将其它阶段的指标通过上述的方式收集起来，作为性能日志；另一方面，在生产环境下，我们一般需要结合具体的性能监控平台，对上述的各项指标进行打点上报，完成线上的 SSR 性能监控服务。

#### 9. SSG/ISR/SPR

有时候对于一些静态站点(如博客、文档)，不涉及到动态变化的数据，因此我们并不需要用上服务端渲染。此时只需要在构建阶段产出完整的 HTML 进行部署即可，这种构建阶段生成 HTML 的做法也叫`SSG`(Static Site Generation，静态站点生成)。

SSG 与 SSR 最大的区别就是产出 HTML 的时间点从 SSR `运行时`变成了`构建时`，但核心的生命周期流程并没有发生变化:

![image-20231129224705612](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-11-29-22-47-image-20231129224705612.png)

这里给一段简单的实现代码:

```ts
// scripts/ssg.ts
// 以下的工具函数均可以从 SSR 流程复用
async function ssg() {
  // 1. 加载服务端入口
  const { ServerEntry, fetchData } = await loadSsrEntryModule(null);
  // 2. 数据预取
  const data = await fetchData();
  // 3. 组件渲染
  const appHtml = renderToString(React.createElement(ServerEntry, { data }));
  // 4. HTML 拼接
  const template = await resolveTemplatePath();
  const templateHtml = await fs.readFileSync(template, 'utf-8');
  const html = templateHtml
  .replace('<!-- SSR_APP -->', appHtml)
  .replace(
    '<!-- SSR_DATA -->',
    `<script>window.__SSR_DATA__=${JSON.stringify(data)}</script>`
  ); 
  // 最后，我们需要将 HTML 的内容写到磁盘中，将其作为构建产物
  fs.mkdirSync('./dist/client', { recursive: true });
  fs.writeFileSync('./dist/client/index.html', html);
}

ssg();
```

接着你可以在`package.json`中加入这样一段 npm scripts:

```json
json
复制代码{
  "scripts": {
    "build:ssg": "npm run build && NODE_ENV=production esno scripts/ssg.ts"  
  }
}
```

这样我们便初步实现了 SSG 的逻辑。当然，除了 SSG，业界还流传着一些其它的渲染模式，诸如`SPR`、`ISR`，听起来比较高大上，但实际上只是 SSR 和 SSG 所衍生出来的新功能罢了，这里简单给大家解释一下:

- `SPR`即`Serverless Pre Render`，即把 SSR 的服务部署到 Serverless(FaaS) 环境中，实现服务器实例的自动扩缩容，降低服务器运维的成本。
- `ISR`即`Incremental Site Rendering`，即增量站点渲染，将一部分的 SSG 逻辑从构建时搬到了 `SSR` 运行时，解决的是大量页面 SSG 构建耗时长的问题。











## 用户认证与授权

### Basic Authentication

基本认证（Basic Authentication）是一种在客户端与服务器之间进行身份验证的简单方式。它通常在 Web 应用程序中用于验证用户，使其能够访问受密码保护的资源或服务。基本认证使用 HTTP 协议的标准头部字段来传递用户名和密码。

基本认证的工作原理如下：

1. **客户端请求**： 客户端（通常是浏览器或应用程序）发送一个 HTTP 请求到服务器，要求访问需要认证的资源。在请求中，客户端在头部中添加了一个名为 "Authorization" 的字段。
2. **编码用户名和密码**： 在 "Authorization" 字段中，客户端将用户名和密码以 "用户名:密码" 的形式组合起来。然后将这个组合进行 Base64 编码。Base64 编码是一种编码方式，它并不是真正的加密，而只是一种将二进制数据转换成可打印字符的方法。
3. **发送认证请求**： 客户端将 Base64 编码后的用户名和密码发送到服务器。注意，虽然这个过程中的用户名和密码是 Base64 编码的，但并没有进行加密，所以并不是安全的传输方式。
4. **服务器验证**： 服务器接收到请求后，会从 "Authorization" 头部中提取 Base64 编码的用户名和密码。然后服务器会对这些凭据进行验证，通常是与存储在服务器上的用户数据库中的凭据进行比较。
5. **返回响应**： 如果凭据是有效的，服务器将返回请求的资源。如果凭据无效，服务器将返回一个需要认证的错误响应，通常是 401 Unauthorized 响应，并要求客户端重新提供有效的凭据。

基本认证的主要特点是简单，但它也有一些安全和隐私方面的局限性：

- **明文传输**：虽然凭据进行了 Base64 编码，但没有进行加密，因此在传输过程中仍然是明文的。这使得凭据可能在网络上被窃取。
- **无法防止中间人攻击**：由于传输是明文的，中间人可以拦截请求并查看凭据，这使得基本认证容易受到中间人攻击。
- **安全性低**：基本认证不提供强大的安全性，因为用户名和密码很容易被窃取，攻击者可以使用暴力破解或其他攻击方法尝试访问资源。

由于这些局限性，基本认证在传输敏感数据时并不是最佳选择。更安全的方法包括使用 HTTPS 加密通信，使用更强大的身份验证方法，如 OAuth 或 JSON Web Token（JWT），以及使用更复杂的会话管理和权限控制机制。



### `Session`

#### 介绍

为了解决Cookie每次传输导致报文头大且前后端都可以修改的问题且cookie在浏览器是可见的，Session应运而生（session是一种方案）。Session的数据只保留在服务器端，客户端无法修改，这样数据的安全性得到一定的保障，数据也无须在协议中每次都被传递。Session信息一般是存储在服务端的，会给浏览器返回一个SessionID之类的标识，下次请求带上SessionID就可以解锁对应的会话信息。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/1/19/16fbb783b3a9fa60~tplv-t2oaga2asx-zoom-in-crop-mark:4536:0:0:0.awebp)

- `工作原理`

  - 客户端带着用户名和密码去访问/login 接口，服务器端收到后校验用户名和密码，校验正确就会在服务器端存储一个 sessionId 和 session 的映射关系。
  - 服务器端返回 response，并且将 sessionId 以 set-cookie 的方式种在客户端，这样，sessionId 就存在了客户端。
  - 客户端发起非登录请求时，假如服务器给了 set-cookie，浏览器会自动在请求头中添加 cookie。
  - 服务器接收请求，分解 cookie，验证信息，核对成功后返回 response 给客户端。

- `优势`

  - 相比 JWT，最大的优势就在于可以主动清除 session 
  - session 保存在服务器端，相对较为安全
  - 结合 cookie 使用，较为灵活，兼容性较好（客户端服务端都可以清除，也可以加密）

- `劣势`

  - cookie+session 在跨域场景表现并不好（不可跨域，domain 变量，需要复杂处理跨域）

  - 如果是分布式部署，需要做多机共享 Session 机制（成本增加）

  - 基于 cookie 的机制很容易被 CSRF

    



#### 实现

●第一种：基于Cookie来实现用户和数据的映射

将口令放在Cookie中。Session的有效期通常较短，普遍的设置是20分钟，如果在20分钟内客户端和服务器端没有交互产生，服务器端就将数据删除。由于数据过期时间较短，且在服务器端存储数据，因此安全性相对较高。那么口令是如何产生的呢？服务器将约定一个键值作为Session的口令，这个值可以随意约定，比如Connect默认采用connect_uid, Tomcat会采用jsessionid等。服务器检查到用户请求Cookie中没有携带该值，它就会为之生成一个值，这个值是唯一且不重复的值，并设定超时时间。



●第二种：通过查询字符串来实现浏览器端和服务器端数据的对应

用户访问http://localhost/pathname时，如果服务器端发现查询字符串中不带session_id参数，就会将用户跳转到http://localhost/pathname?session_id=12344567这样一个类似的地址。如果浏览器收到302状态码和Location报头，就会重新发起新的请求。这样，新的请求到来时就能通过Session的检查，除非内存中的数据过期。

有的服务器在客户端禁用Cookie时，会采用这种方案实现退化。通过这种方案，无须在响应时设置Cookie。但是这种方案带来的风险远大于基于Cookie实现的风险，因为只要将地址栏中的地址发给另外一个人，那么他就拥有跟你相同的身份。



- 第三种：利用HTTP请求头中的ETag，自己上网搜





#### session的安全

##### 介绍

主要指如何让这个口令(key-value)更加安全。

尽管我们的数据都放置在后端了，但是Session的口令（key-value）依然保存在客户端，这里会存在口令被盗用的情况。

而且Web应用的用户十分多情况下如果自行设计的随机算法的一些口令值就有理论机会命中有效的口令值。





##### 解决方案

###### 方案一 私钥加密value

将这个口令的value通过私钥加密进行签名，使得伪造的成本较高。该方法被Connect中间件框架所使用，保护好私钥，就是在保障自己Web应用的安全。

![image-20230820154049153](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-08-20-15-40-image-20230820154049153.png)

在响应时，设置session值到Cookie中或者跳转URL中：

![image-20230820154112931](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-08-20-15-41-image-20230820154112931.png)

如果签名非法，我们将服务器端的数据立即过期即可



###### 方案二 添加进客户端独有信息到value里

将客户端的某些独有信息与口令作为原值，然后签名，这样攻击者一旦不在原始的客户端上进行访问，就会导致签名失败。这些独有信息包括用户IP和用户代理（User Agent）。







##### 如果是xss攻击

如果是xss攻击直接获取cookie，那么上面那些解决方案都是扯淡。

比如这样：

![image-20230820154500486](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-08-20-15-45-image-20230820154500486.png)





#### session存储

- 如果session存在内存里的弊端：

  将数据存放在内存中将会带来极大的隐患，如果用户增多，我们很可能就接触到了内存限制的上限，并且内存中的数据量加大，必然会引起垃圾回收的频繁扫描，引起性能问题。

  如果开启多进程，用户请求的连接将可能随意分配到各个进程中，Node的进程与进程之间是不能直接共享内存的，用户的Session可能会引起错乱。

  

- 采用第三方缓存来存储Session：目前常用的工具是Redis、Memcached等。

  通过这些高效的缓存，Node进程无须在内部维护数据对象，垃圾回收问题和内存限制问题都可以迎刃而解，并且这些高速缓存设计的缓存过期策略更合理更高效，比在Node中自行设计缓存策略更好。

  存在的问题：

  会引起网络访问。访问本地磁盘中的数据速度要慢，因为涉及到握手、传输以及网络终端自身的磁盘I/O等，但依然会采用这些高速缓存的理由有以下几条：

  ❑ Node与缓存服务保持长连接，而非频繁的短连接，握手导致的延迟只影响初始化。

  ❑ 高速缓存直接在内存中进行数据存储和访问。

  ❑ 缓存服务通常与Node进程运行在相同的机器上或者相同的机房里，网络速度受到的影响较小。











### `JWT`

##### 相关的概念介绍

> 由于详细的介绍 JWT 会占用大量文章篇幅，也不是本文的重点。所以这里只是简单介绍一下。主要是和 Session 方式做一个对比。关于 JWT 详细的介绍可以参考`https://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html`



JWT有一个缺点就是无法在使用过程中废止某个token，或者更换token的权限。也就是说，一旦JWT签发了，在到期之前会始终有效，除非服务器部署额外的逻辑。其实JWT放在Cookie里也没问题，并且请求的时候会自动带上JWT。



##### JWT 的原理

服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样:

```json
{
  "姓名": "森林",
  "角色": "搬砖工",
  "到期时间": "2020年1月198日16点32分"
}
```

以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认证用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名。

服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。

##### JWT 的格式

举例

```
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImxpdWppYW5naG9uZyIsImlhdCI6MTYzMDcyNTU0NiwiZXhwIjoxNjMwNzI5MTQ2fQ.tCZobphzBo0atE5cXLVI-9NxE-PUbs9dY1gPSrty5pw
```

它是字符串，中间用点（.）分隔成三个部分。



JWT 的三个部分依次如下:

第一部分为header：`eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9`。Base64解码后会变成一个JSON串 ：

```json
{"alg":"HS256","typ":"JWT"}
```

typ指的是类型，alg指的是加密算法。一般JWT的header部分只有这两个属性。



第二部分为payload：`eyJ1c2VybmFtZSI6ImxpdWppYW5naG9uZyIsImlhdCI6MTYzMDcyNTU0NiwiZXhwIjoxNjMwNzI5MTQ2fQ`。Base64解码后会变成一个JSON串 ：

```json
{"username":"liujianghong","iat":1630725546,"exp":1630729146}
```

在payload中是可以添加一些公共信息的，比如用户名。在JWT的标准里，payload有以下几处申明。

- iss：JWT签发者。
- sub：JWT所面向的用户。
- aud：接收JWT的一方。
- exp：JWT的过期时间，这个过期时间必须大于签发时间。
- nbf：定义在什么时间之前，该JWT都是不可用的。
- iat：JWT的签发时间。
- jti：JWT的唯一身份标识，主要用来作为一次性token，从而回避重放攻击。



第三部分为signature：`tCZobphzBo0atE5cXLVI-9NxE-PUbs9dY1gPSrty5pw`。signature部分的生成是由Base64编码之后的header和payload通过小圆点连接起来，再通过加密算法（需要一个secret）生成的。过程可以用如下语句表述：

```stylus
HMACSHA256( base64UrlEncode(header) + "." + base64UrlEncode(payload), secret)
```







##### JWT相比Session

- 安全性（两者均有缺陷）
- RESTful API，JWT 优胜，因为 RESTful API 提倡无状态，JWT 符合要求
- 性能（各有利弊，因为 JWT 信息较强，所以体积也较大。不过 Session 每次都需要服务器查找，JWT 信息都保存好了，不需要再去查询数据库）
- 时效性，Session 能直接从服务端销毁，JWT 只能等到时效性到了才会销毁（修改密码也无法阻止篡夺者的使用）

##### `jsonwebtoken`

由于 RESTful API 提倡无状态，而 JWT 又恰巧符合这一要求，因此我们采用`JWT`来实现用户信息的授权与认证。

项目中采用的是比较流行的`jsonwebtoken`。具体使用方式可以参考`https://www.npmjs.com/package/jsonwebtoken`



### 单点登录

实现单点登录的方式有很多，介绍3种实现方式：同域SSO、同父域SSO以及跨域SSO。

同域SSO 和 同父域SSO （都是利用cookie跨站的特点）。



#### 跨域SSO

##### 介绍

如果App之间的同级域不一样，父域也不一样，在Cookie不共享的情况下，该如何做到单点登录呢？集中式认证服务（Central Authentication Service，CAS）架构可以解决这样的问题。目前业界做SSO鉴权的方案多数是采用了CAS架构。

CAS架构分为两部分：一部分是CAS客户端；另一部分是CAS服务端。CAS客户端是受保护的应用，即需要鉴权的系统。CAS服务端负责鉴权工作，通常情况下，每个公司都有一个SSO统一平台，它就是CAS服务端。



##### ST、TGT和TGC

ST（Service Ticket）：CAS服务端生成的票据，可以理解为一张通行证。这个通行证只能用一次并且有过期时间。

TGT（Ticket Granting Ticket）：TGT就是SessionID，后续用它来验证是否需要创建新的Session，即是否需要再次跳转到SSO的登录界面，填写用户名和密码）。TGT是种在SSO域名下面的。

TGC（Ticket Granting Cookie）：Cookie中对应TGT的键值。



##### 第一次访问App时

假设现在有两个App，一个App，另一个App2。用户两个平台都没有登录过。

执行顺序如图所示。

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-15-54-image-20231213155434107.png" alt="image-20231213155434107" style="zoom: 33%;" />



##### 第二次访问App时

当用户再次访问App时，由于已经在Cookie里种了token，请求会自动带上Cookie在App服务端进行验证，如果验证通过，则直接返回结果。

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-16-09-image-20231213160910185.png" alt="image-20231213160910185" style="zoom:33%;" />





##### 登录App后，用户第一次访问App2

![image-20231213161144620](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-16-11-image-20231213161144620.png)



##### 用实际生活场景模拟CAS架构原理

假如我入职了一家新公司，进办公区和食堂都需要工卡。而工卡需要到公司前台去办理。

办理临时工卡的过程与CAS原理的对应关系如下：

- 我代表用户。
- 办公区域和食堂代表受保护的App和App2。
- 前台代表CAS服务。临时工卡代表ST，只能用一次的临时票据。
- Excel表代表CAS创建的Session，记录着TGT。

![image-20231213162307099](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-16-23-image-20231213162307099.png)





### 授权协议OAuth 2.0

OAuth 2.0标准目前广泛应用于第三方平台授权场景。OAuth 2.0的授权及验证流程：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-16-31-image-20231213163143341.png" alt="image-20231213163143341" style="zoom:33%;" />

1）博客园跳转到QQ统一授权登录页面，URL会带有一些参数。

​		<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-16-38-image-20231213163856823.png" alt="image-20231213163856823" style="zoom:33%;" />

2）用户扫码登录，表示同意授权。

3）QQ服务器收到同意授权后，生成一个授权码，返回给博客园。

4）博客园携带上一步返回的授权码，再次向QQ认证服务器发起请求，这次是索要token。

​		<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-16-39-image-20231213163938228.png" alt="image-20231213163938228" style="zoom:33%;" />

5）QQ认证服务器返回token（一个是授权token，一个是刷新token）（QQ返回一些json数据）。

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-16-40-image-20231213164008838.png" alt="image-20231213164008838" style="zoom:33%;" />

最后，博客园带着access_token向QQ索要用户信息。



#### 为什么第一步需要带上state

假如没有state参数，现在有两个用户，一个正常用户 和 一个攻击者，具体过程如下：

1）攻击者登录博客园网站时，选择用第三方平台QQ登录。由于他之前登录过QQ，因此QQ直接向询问是否授权博客园。李四在同意授权后，截获了授权码。

2）攻击者打造了一个Web页面，触发向QQ发起申请token的请求，而请求中的授权码，就是刚刚截获的授权码。攻击者把这个Web页面挂在了网上，等待被骗者。

3）正常用户 虽然已经登录了博客园，但是没有绑定第三方平台的账号。有一天 正常用户 无意间点击了攻击者的页面，触发了向QQ平台索要access_token的请求，因为请求中的授权码是攻击者的，所以拿回来的access_token也是攻击者的。这样正常用户的博客园就绑定了攻击者的QQ账号。

4）攻击者 可以用自己的账号冒充正常用户进行一系列操作了。

如果在请求中加了state参数，因为state参数具有唯一性、时效性、关联性，所以这种具有欺骗性的请求很容易被识别出来。











## 数据上传与安全

### 内存限制

#### 介绍

在解析表单、JSON和XML部分，我们采取的策略是先保存用户提交的所有数据，然后再解析处理，最后才传递给业务逻辑。这种策略存在潜在的问题是，它仅仅适合数据量小的提交请求，一旦数据量过大，将发生内存被占光的情况。哪怕每次提交1 MB的内容，只要并发请求数量一大，内存就会很快地被吃光。

#### 解决方案

❑ 限制上传内容的大小，一旦超过限制，停止接收数据，并响应400状态码。

❑ 通过流式解析，将数据流导向到磁盘中，Node只保留文件路径等小数据





### 防止CSRF -- 看浏览器CSRF那



## 路由

### 路由解析

就是对web请求的预处理，有很多种策略可以选择。

#### 文件路径模式

1．静态文件

URL的路径与网站目录的路径一致。这种路由的处理方式十分简单，将请求路径对应的文件发送给客户端即可。比如vite里用的mock插件就是这种模式。



2.动态文件（看不懂）

在MVC模式流行起来之前，根据文件路径执行动态脚本也是基本的路由方式，它的处理原理是Web服务器根据URL路径找到对应的文件，如/index.asp或/index.php。Web服务器根据文件名后缀去寻找脚本的解析器，并传入HTTP请求的上下文。解析器执行脚本，并输出响应报文，达到完成服务的目的。现今大多数的服务器都能很智能地根据后缀同时服务动态和静态文件。这种方式在Node中不太常见，主要原因是文件的后缀都是．js，分不清是后端脚本，还是前端脚本，这可不是什么好的设计。而且Node中Web服务器与应用业务脚本是一体的，无须按这种方式实现。



#### MVC模式

MVC模型的主要思想是将业务逻辑按职责分离

❑ 控制器（Controller），一组行为的集合。

❑ 模型（Model），数据相关的操作和封装。

❑ 视图（View），视图的渲染。

这是目前最为经典的分层模式：![image-20230820190742270](https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-08-20-19-07-image-20230820190742270.png)

如何根据URL做路由映射，这里有两个分支实现：

一种方式是通过手工关联映射，比如`use('/user',userController)`

一种是自然关联映射，就是约定式路由。比如以/user/setting/12/1987为例，它会按约定去找controllers目录下的user文件，将其require出来后，调用这个文件模块的setting()方法，而其余的值作为参数直接传递给这个方法。





### RESTful API 

#### 简介

`REST`的全称是`Representational state transfer`。中文含义为表现层状态转化。它描述了一个系统如何与另一个交流。具体如下:

- Representational: 数据的表现形式(JSON、XML...)
- state: 当前状态或者数据
- transfer: 数据传输

符合REST规范的设计，我们称为RESTful设计。它的设计哲学主要将服务器端提供的内容实体看作一个资源，并表现在URL上。

<font color="red">RESTful与MVC设计并不冲突，而且是更好的改进。相比MVC, RESTful只是将HTTP请求方法也加入了路由的过程，以及在URL路径上体现得更资源化（即url路径上不再出现操作的词汇如`add`、`delete`）。</font>

`REST` 一般通过 Http 方法`GET`, `DELETE`, `POST` 和 `PUT`等 来操作资源。

Query和Params可以结合使用。例如，在RESTful API中，Query通常用于过滤、排序和分页等操作，而Params则用于传递实际的数据。



#### 六个约束:

- 客户-服务器(Client-Server)

  关注点分离。服务端专注数据存储，提升了简单性，前端专注用户界面，提升了可移植性。

- 无状态(Stateless)

  所有用户会话信息都保存在客户端。每次请求必须包括所有信息，不能依赖上下文信息。服务端不用保存会话信息，提升了简单性、可靠性、可见性。

- 缓存(Cache)

  所有服务端响应都要被标为可缓存或不可缓存，减少前后端交互，提升了性能。

- 统一接口(Uniform Interface)

  接口设计尽可能统一通用，提升了简单性、可见性。接口与实现解耦，使前后端可以独立开发迭代。

- 分层系统(Layered System)

- 按需代码(Code-On-Demand)

#### 行业内的最佳实践

##### `请求设计规范`

- `URI 使用名词`，尽量使用复数，如/users
- URI 使用`嵌套`表示`关联关系`，如/users/123/repos/234
- 使用`正确的 HTTP 方法`，如 GET/POST/PUT/DELETE

##### `响应设计规范`

- `查询`
- `分页`
- `字段过滤`

如果记录数量很多，服务器不可能都将它们返回给用户。API 应该提供参数，过滤返回结果。下面是一些常见的参数（包括上面的查询、分页以及字段过滤）：

```ini
?limit=10：指定返回记录的数量
?offset=10：指定返回记录的开始位置。
?page=2&per_page=100：指定第几页，以及每页的记录数。
?sortby=name&order=asc：指定返回结果按照哪个属性排序，以及排序顺序。
?animal_type_id=1：指定筛选条件
```

- `状态码`
- `错误处理`

就像 HTML 的出错页面向访问者展示了有用的错误消息一样，API 也应该用之前清晰易读的格式来提供有用的错误消息。

比如对于常见的提交表单，当遇到如下错误信息时：

```json
{
    "error": "Invalid payoad.",
    "detail": {
        "surname": "This field is required."
    }
}
```

接口调用者很快就能定位到错误原因。

##### `安全`

- `HTTPS`
- `鉴权`

RESTful API 应该是无状态。这意味着对请求的认证不应该基于`cookie`或者`session`。相反，每个请求应该带有一些认证凭证。

- `限流`

为了避免请求泛滥，给 API 设置`速度限制`很重要。为此 `RFC 6585` 引入了 HTTP 状态码`429（too many requests）`。加入速度设置之后，应该给予用户提示。







### query 

#### 介绍

是url ？ 后面的参数，以键值对的形式传递给服务器。在后端路由中从url里面取，前端路由可以直接.query里取是因为插件本身帮你封装好了。

跟method是没有关系的，就是跟在url后面。

#### 使用

##### 发请求

###### axios

get请求时使用params参数（params参数只有在get时才会自动把这些参数放到url后面。）



###### fetch



##### 接收请求

###### koa

在koa中，获取GET请求数据源头是koa中request对象中的query方法或querystring方法，query返回是格式化好的参数对象，querystring返回的是请求字符串，由于ctx对request的API有直接引用的方式，所以获取GET请求数据有两个途径。

- 1.是从上下文中直接获取
  - 请求对象ctx.query，返回如 `{ a:1, b:2 }`
  - 请求字符串 ctx.querystring，返回如 a=1&b=2
- 2.是从上下文的request对象中获取
  - 请求对象ctx.request.query，返回如 `{ a:1, b:2 }`
  - 请求字符串 ctx.request.querystring，返回如 `a=1&b=2`





### params

#### 介绍

param 是 直接跟在url后面的参数（需要在路由那里预先设置好占位符），前端路由和后端路由都可以从params.id里面取。

感觉这种方式不是http协议的参数形式，是路由会对路径进行导致可以使用这种形式。所以无论get/post方法都能使用这个方式。



#### 使用

##### 发请求

###### axios

直接在路径上拼接就行：`/api/codex/fly_bird`这里的`fly_bird`就会被后端提取出来。



###### fetch



##### 接收请求

###### koa

路径中写比如`router.**get**('/api/codex/:game'）`，然后ctx.params就能拿到`{game: fly_bird}`





### body

#### 介绍

请求体，get形式没有请求体。

#### 使用

##### 发请求

###### axios

axios里的data参数就是请求体里的data，根据 content-Type不同会有不同的形式。





##### 接收请求

###### koa

参考https://chenshenhai.github.io/koa2-note/note/request/post.html 或者使用中间件：https://www.npmjs.com/package/koa-bodyparser后直接ctx.request.body。





## 部署

### 静态部署&容器部署

1. **定义**:
   - 静态部署：在静态部署中，应用程序的所有组件（包括前端、后端、静态文件、配置等）被编译成静态文件，并直接部署到服务器或静态文件服务器。每次更新应用程序时，都需要重新构建和部署整个应用程序。静态部署不依赖于运行时环境，即不需要运行应用程序的服务器。
   - 容器部署：在容器部署中，应用程序及其所有依赖项（如库、运行时环境、配置等）被打包到一个独立的容器中。容器是一种虚拟化技术，它可以在任何支持容器引擎的系统上运行，提供了一个隔离的运行环境。每个容器都包含了应用程序和其所需的运行时环境，使应用程序在不同的环境中具有相同的行为。
2. **灵活性**:
   - 静态部署：静态部署在部署时非常快速，因为只需要将编译后的静态文件上传到服务器。然而，每次更新应用程序时，都需要重新构建和部署整个应用程序，这可能会比较耗时。
   - 容器部署：容器部署具有更好的灵活性。一旦将应用程序打包到容器中，可以轻松地在不同的环境中部署和运行容器，而不必重新构建应用程序。容器还提供了更好的可移植性，因为可以将容器在开发、测试和生产环境之间无缝迁移。
3. **依赖性管理**:
   - 静态部署：静态部署需要确保在服务器上安装了所有应用程序所需的依赖项和运行时环境。这可能导致一些依赖冲突或版本问题，需要手动处理。
   - 容器部署：容器将应用程序及其依赖项隔离在一个独立的运行时环境中，避免了依赖冲突问题。容器中的所有依赖项都由容器镜像自带，不会受到宿主系统的影响。
4. **部署复杂性**:
   - 静态部署：静态部署相对较简单，只需要将静态文件上传到服务器即可。但是，每次更新都需要手动重新部署整个应用程序。
   - 容器部署：容器部署需要更多的配置和管理，但它提供了更好的自动化和持续集成/持续部署（CI/CD）支持。容器可以通过自动化工具（如Docker Compose和Kubernetes）进行自动化管理和部署。

选择静态部署还是容器部署取决于您的具体需求和项目要求。静态部署适用于简单的静态网站和轻量级应用程序，而容器部署更适用于复杂的应用程序和需要更好可移植性、扩展性和自动化管理的项目。







### 部署前端应用

#### 覆盖式发布

##### 存在的问题

1. 比如将修改后的两个文件上传到服务器，覆盖旧的文件。在上传的过程中，两个文件不可能同时被覆盖，必定存在着先后顺序，包括两种情况。index.html先被覆盖，style.css后被覆盖。在两个资源覆盖期间，如果有用户访问了页面，那么他访问的将是新的index.html和旧的style.css，结果就是页面上的bar没有样式修饰。style.css先被覆盖，index.html后被覆盖，在两个资源覆盖期间，如果有用户访问了页面，那么他访问的将是新的style.css和旧的index.html，结果就是页面上的foo没有样式修饰。

   以上仅列举了在文件数量和类型比较简单的情况下，使用覆盖式发布可能导致的问题。随着页面依赖的文件数量增加，不仅部署的时间会更长，部署时文件覆盖的先后顺序也更加多变。如果在页面依赖的某个.js文件里，某部分代码依赖了DOM结构，那么.html文件中的变更可能导致页面某个功能不可用，这是比样式错乱更为严重的问题。

   

2. 当部署的代码出现问题时，服务器上的资源不能直接回滚到上一次的状态。开发人员必须在本地将代码回退到之前的状态，然后重新进行构建打包，重新上传资源才能实现回滚。整个回滚期间会耗费大量的时间和精力，并且在回滚完成之前，生产环境的故障依然存在。

 



##### 解决方案：文件加hash值

先将style_v2.css文件上传到服务器，然后将index.html文件上传到服务器，更新入口页面。当style_v2.css文件被上传到服务器时，旧的index.html文件依赖的依然是style_v1.css文件，并不依赖style_v2.css文件；当新的index.html文件被上传到服务器时，style_v2.css文件已经被上传到服务器，不会出现资源无法访问的情况。因此，非覆盖式发布不会出现新旧文件交替依赖的情况，由此可以有效避免资源上传间隔导致的样式错乱问题。

 



index.html还是覆盖的

它的缺点是会在服务器上积累大量的无用资源，该问题只需要定时清理即可解决。当index.html作为入口页时，不能添加哈希值作为文件后缀，回滚机制并不完善

 

 

#### 静态资源部署

浏览器在进行资源加载时，会默认在请求报头中携带cookie，它会增大建立连接的请求体积，增加额外的带宽开销。同时，浏览器限制单个子域名的并发请求数量，这也会影响页面的加载速度。

 

![underline](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdCb3g9IjAgMCAyMCAyMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTAiIGN5PSIxMCIgcj0iMTAiIGZpbGw9IiM3Nzc3NzciIGZpbGwtb3BhY2l0eT0iMC4xNyIvPgo8cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTEzLjM1MDUgMTIuMDgzMkgxMi4xMDQ3TDExLjU3MzggMTAuNTM0SDguNTI5NjhMNy45OTg4NCAxMi4wODMySDYuNzUzMDFMOS41ODA1MSA0LjM2OTg3SDEwLjUyM0wxMy4zNTA1IDEyLjA4MzJaTTExLjI0ODggOS41MzczN0wxMC4wNzg4IDYuMTE0MDRMOC44NzYzNCA5LjUzNzM3SDExLjI0ODhaTTEzLjMzMzQgMTMuNzVINi42NjY3NVYxNUgxMy4zMzM0VjEzLjc1WiIgZmlsbD0iIzk5QTBBQSIvPgo8L3N2Zz4K)

在浏览器向服务器请求加载静态资源时，需要与服务器建立连接。在资源下载期间不仅会占用浏览器的带宽，也会占用服务器的带宽。每个服务器可建立的链接数和带宽都是有限的。当下载资源的并发连接数超出负载后，不仅服务器有限的带宽会被瓜分，新增的接口和资源连接也没办法及时响应。

 

![underline](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdCb3g9IjAgMCAyMCAyMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTAiIGN5PSIxMCIgcj0iMTAiIGZpbGw9IiM3Nzc3NzciIGZpbGwtb3BhY2l0eT0iMC4xNyIvPgo8cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTEzLjM1MDUgMTIuMDgzMkgxMi4xMDQ3TDExLjU3MzggMTAuNTM0SDguNTI5NjhMNy45OTg4NCAxMi4wODMySDYuNzUzMDFMOS41ODA1MSA0LjM2OTg3SDEwLjUyM0wxMy4zNTA1IDEyLjA4MzJaTTExLjI0ODggOS41MzczN0wxMC4wNzg4IDYuMTE0MDRMOC44NzYzNCA5LjUzNzM3SDExLjI0ODhaTTEzLjMzMzQgMTMuNzVINi42NjY3NVYxNUgxMy4zMzM0VjEzLjc1WiIgZmlsbD0iIzk5QTBBQSIvPgo8L3N2Zz4K)

为了解决上述问题，开发人员采用了动静分离的方案对网站进行优化。动静分离指将网站的静态资源托管到其他服务器上，与网站应用的服务器隔离开，提高用户访问静态代码的速度，降低源服务器的压力。用于托管静态资源的服务器叫内容分发网络（Content Delivery Network，CDN），它可以加快用户访问网络资源的速度和稳定性，减轻源服务器的访问压力。CDN的原理是在网络各处放置节点，在互联网的基础上构建一层智能虚拟网络，从而实时地根据网络流量、各节点的连接和负载状况以及响应时间等信息，将用户的请求重新导向离用户最近的服务节点，提高网站的访问速度。

 

![underline](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdCb3g9IjAgMCAyMCAyMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTAiIGN5PSIxMCIgcj0iMTAiIGZpbGw9IiM3Nzc3NzciIGZpbGwtb3BhY2l0eT0iMC4xNyIvPgo8cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTEzLjM1MDUgMTIuMDgzMkgxMi4xMDQ3TDExLjU3MzggMTAuNTM0SDguNTI5NjhMNy45OTg4NCAxMi4wODMySDYuNzUzMDFMOS41ODA1MSA0LjM2OTg3SDEwLjUyM0wxMy4zNTA1IDEyLjA4MzJaTTExLjI0ODggOS41MzczN0wxMC4wNzg4IDYuMTE0MDRMOC44NzYzNCA5LjUzNzM3SDExLjI0ODhaTTEzLjMzMzQgMTMuNzVINi42NjY3NVYxNUgxMy4zMzM0VjEzLjc1WiIgZmlsbD0iIzk5QTBBQSIvPgo8L3N2Zz4K)

静态资源被托管到CDN上，资源的更新和缓存策略就由CDN服务商制定，从而引发了资源更新问题。不同的CDN服务商会有不同的资源管理策略

 

![underline](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdCb3g9IjAgMCAyMCAyMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTAiIGN5PSIxMCIgcj0iMTAiIGZpbGw9IiM3Nzc3NzciIGZpbGwtb3BhY2l0eT0iMC4xNyIvPgo8cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTEzLjM1MDUgMTIuMDgzMkgxMi4xMDQ3TDExLjU3MzggMTAuNTM0SDguNTI5NjhMNy45OTg4NCAxMi4wODMySDYuNzUzMDFMOS41ODA1MSA0LjM2OTg3SDEwLjUyM0wxMy4zNTA1IDEyLjA4MzJaTTExLjI0ODggOS41MzczN0wxMC4wNzg4IDYuMTE0MDRMOC44NzYzNCA5LjUzNzM3SDExLjI0ODhaTTEzLjMzMzQgMTMuNzVINi42NjY3NVYxNUgxMy4zMzM0VjEzLjc1WiIgZmlsbD0iIzk5QTBBQSIvPgo8L3N2Zz4K)

协商缓存虽然也使用本地缓存，但在校验资源是否过期时依然会与服务建立连接。协商缓存虽然节约了资源下载时的带宽，但依然需要占用服务器资源进行资源的过期校验。部分CDN服务商为了降低服务器的开销，节约运营成本，会选择使用强缓存来代替协商缓存。同时，CDN边缘节点的资源更新在很大程度上依赖源站的资源下发。以上两点都会导致资源更新出现延迟。假设有一个名为style.css的资源，CDN服务商通过强缓存的方式将其缓存到了浏览器端，过期时间设置为1天。那么在1天之内，style.css无法进行更新。即使CDN服务商没有使用强缓存，或者用户手动清空了浏览器缓存重新加载，CDN的资源下发也会存在延迟。在最新的style.css由源站下发到边缘节点之前，用户访问CDN边缘节点时获取的依然是旧版的style.css。

 

![underline](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdCb3g9IjAgMCAyMCAyMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTAiIGN5PSIxMCIgcj0iMTAiIGZpbGw9IiM3Nzc3NzciIGZpbGwtb3BhY2l0eT0iMC4xNyIvPgo8cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTEzLjM1MDUgMTIuMDgzMkgxMi4xMDQ3TDExLjU3MzggMTAuNTM0SDguNTI5NjhMNy45OTg4NCAxMi4wODMySDYuNzUzMDFMOS41ODA1MSA0LjM2OTg3SDEwLjUyM0wxMy4zNTA1IDEyLjA4MzJaTTExLjI0ODggOS41MzczN0wxMC4wNzg4IDYuMTE0MDRMOC44NzYzNCA5LjUzNzM3SDExLjI0ODhaTTEzLjMzMzQgMTMuNzVINi42NjY3NVYxNUgxMy4zMzM0VjEzLjc1WiIgZmlsbD0iIzk5QTBBQSIvPgo8L3N2Zz4K)

资源更新的延迟使得有时用户访问的页面并不是预期的页面，可能给用户造成困扰，可以借助前文提到的文件哈希值来解决这个问题

 

![underline](data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAiIGhlaWdodD0iMjAiIHZpZXdCb3g9IjAgMCAyMCAyMCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGNpcmNsZSBjeD0iMTAiIGN5PSIxMCIgcj0iMTAiIGZpbGw9IiM3Nzc3NzciIGZpbGwtb3BhY2l0eT0iMC4xNyIvPgo8cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTEzLjM1MDUgMTIuMDgzMkgxMi4xMDQ3TDExLjU3MzggMTAuNTM0SDguNTI5NjhMNy45OTg4NCAxMi4wODMySDYuNzUzMDFMOS41ODA1MSA0LjM2OTg3SDEwLjUyM0wxMy4zNTA1IDEyLjA4MzJaTTExLjI0ODggOS41MzczN0wxMC4wNzg4IDYuMTE0MDRMOC44NzYzNCA5LjUzNzM3SDExLjI0ODhaTTEzLjMzMzQgMTMuNzVINi42NjY3NVYxNUgxMy4zMzM0VjEzLjc1WiIgZmlsbD0iIzk5QTBBQSIvPgo8L3N2Zz4K)

浏览器在从CDN边缘节点尝试加载style_2e87e.css时，会发生两种情况。一种是CDN边缘节点已经收到了源站下发的style_2e87e.css资源，此时直接返回该资源，浏览器就能获取最新的资源。另一种是CDN边缘节点尚未收到源站下发的style_2e87e.css资源，此时会触发CDN的回源机制，同样可以返回最新的资源。CDN的回源指CDN服务器在收到一个资源请求时，发现自己没有缓存该资源，从而从它的上层服务器或者根服务器加载该资源的过程。回源有效解决了在源站的资源下发间隔内，边缘节点资源缺失的问题，进一步提升了CDN的稳定性。通过为文件添加哈希后缀、利用浏览器资源的缓存机制和CDN的回源策略，开发人员可以有效解决资源更新延迟的问题。

 





 





# 数据库

在不同场景下，不同类型的数据存储的地方也不一样，比如一些重要数据需要长期存储，那么存储在数据库里比较合适；一些日志数据，存储在Elasticsearch中比较合适；一些数据存取需要速度更快一些，利用Redis进行存储最为合适。







## MySQL

下载地址：https://dev.mysql.com/downloads/mysql/下载后进行本地安装。

打开控制台，输入命令`mysql -u root -p`，接着输入登录密码，如果出现mysql命令行，说明安装成功。

推荐一款名为Sequel Ace的数据库客户端，对数据的增删改查操作确实非常方便。



## Elasticsearch

### 介绍

#### 介绍

官方文档：https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/index.html

Elasticsearch可以简单理解为一个数据库，其对于大数据的搜索性能优势非常明显。在一些实际业务场景中，可能需要临时存储大量的数据，并且经常进行查询操作，比如项目中的各种日志，包括access-log、api-log、error-log等，甚至还需要进行各种分析。如果把这些数据存储到数据库里有些不妥，原因是日志具有时效性，最近存储的日志具有分析价值，如果日志久远，就会变成垃圾数据，那么这些垃圾数据就不应该占据磁盘空间了。数据库应该用于存储持久性数据。在这种情况下，使用Elasticsearch是最合适的，一般在公司内部，会将Elasticsearch部署到一台独立的服务器上，由OP人员维护，并且Elasticsearch上的日志是有保存期限的，一般是两个月（不同场景下，日志保存期限不一样），过了期限，日志将被删除。



#### 和数据库的对比

Elasticsearch是一个搜索引擎，虽然也有存储数据的功能，但是两者在使用场景以及能解决的问题方面都不相同。关系型数据库更适合OLTP（一种以事务元作为数据处理的单位、人机交互的计算机应用系统，最大优点是可以即时处理输入的数据并及时回答）业务场景。而Elasticsearch适合OLAP的场景（它使分析人员能够迅速、一致、交互地从各个方面观察信息，以达到深入理解数据的目的），比如海量日志分析和检索等。虽然Elasticsearch和关系型数据库在很多方面有所不同，但是对于开发人员来说，如果对于数据库比较熟悉，对于Elasticsearch比较陌生，也可以通过类比的方式进行学习。在关系型数据库中，有几个重要的概念：Table（表）、Schema（结构、定义）、Row（数据行）、Column（数据列）、SQL（查询等语句）。在Elasticsearch中也有几个重要概念：Index（索引）、Type（类型）、Mapping（索引定义）、Document（文档）、Field（字段）、DSL（查询等语句）。两者可以进行对比理解：

<img src="https://picbed-1306720359.cos.ap-guangzhou.myqcloud.com/upic/2023-12-13-17-59-image-20231213175925560.png" alt="image-20231213175925560" style="zoom:33%;" />



### 操作

下载地址：https://www.elastic.co/cn/downloads/elasticsearch。下载后将其解压，进入根目录下执行./bin/elasticsearch命令即可启动。如果看到started，说明启动成功了。

推荐一款ElasticSearch客户端，用于更直观地查看数据：名为ElasticSearch Head的Chrome插件。





